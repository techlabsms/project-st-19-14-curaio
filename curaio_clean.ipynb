{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curaio - TechLabs Project Summer Term 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing needed packages and libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pytrends.request import TrendReq\n",
    "import pytrends\n",
    "from random import randint\n",
    "import pmdarima as pm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing functions used during the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usdata(kw_list):\n",
    "    \"\"\"takes keyword list as input and returns DataFrame\n",
    "    containing ili rates for the state and Google Trends \n",
    "    data for the keywords\"\"\"\n",
    "    \n",
    "    # ili data\n",
    "    us_ili = pd.read_csv(\"ili_national_level.csv\", header=0)\n",
    "    us_ili[\"date\"] = pd.to_datetime(us_ili.week.astype(str) + us_ili.year.astype(str).add(\"-0\"), format=\"%W%Y-%w\")\n",
    "    us_ili.set_index(\"date\", inplace=True)\n",
    "    ili = us_ili.shift(-1, freq='W')\n",
    "       \n",
    "    \n",
    "    # Google Trends\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    pytrends.build_payload(kw_list, cat=0, timeframe=\"2015-01-11 2019-07-07\", geo=\"US\")\n",
    "    trends = pytrends.interest_over_time()\n",
    "    trends = trends.drop(\"isPartial\", axis=1)\n",
    "    \n",
    "    # merge the dataframes on the Datetimeindex\n",
    "    merged = trends.join(ili)\n",
    "    merged[\"unweighted_ili\"] = merged[\"unweighted_ili\"].interpolate(method=\"linear\")\n",
    "    merged = merged.drop(merged.tail(4).index, inplace=False)\n",
    "    merged = merged.asfreq(\"W\")\n",
    "    \n",
    "    return merged\n",
    " \n",
    "    \n",
    "def rmse(testdf, preddf):\n",
    "    \"\"\"takes two dataframes as input: testdf containing (true) test data \n",
    "    and preddf containing predictions made with a forecasting model;\n",
    "    returns the root mean squared error as evaluation metric\"\"\"\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(testdf, preddf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and aim of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the project is to predict disease rates, more precisely influenza-like illnesses rates (ILI rates). On the one hand historical time series data were used, on the other hand the data basis was extended by Google Trends data. According to [Google News Lab](https://medium.com/google-news-lab/what-is-google-trends-data-and-what-does-it-mean-b48f07342ee8) these data are  \n",
    "> \"normalized Trends data. This means that when we look at search interest over time for a topic, weâ€™re looking at that interest as a proportion of all searches on all topics on Google at that time and location\".\n",
    "\n",
    "The data is indexed to 100, where 100 is the maximum search interest for the time and location selected. The idea was that people may google typical flu symptoms at the onset of a cold or flu even before the disease fully manifests itself. The explanatory variables for the ILI rates were therefore defined as a combination of keywords containing such typical symptoms of influenza. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition and engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, it was planned to carry out the project on the basis of data for Germany. However, due to the lack of freely accessible influenza data, we decided to do the project for the USA. The ILI rates could be obtained using the R Package [cdcfluview](https://rdrr.io/cran/cdcfluview/) and the ilinet function. This function retrieves data from the CDC FluView Portal containing, inter alia, in-season and past seasons' national, regional, and state-level outpatient illness surveillance data from ILINet (Influenza-like Illness Surveillance Network). <br><br>\n",
    "The Google Trends data were obtained using Python's [pytrends](https://github.com/GeneralMills/pytrends), an unofficial pseudo API for extracting Google Trends data. As a combination of keywords, the following typical symptoms were identified:\n",
    "- fever\n",
    "- flu\n",
    "- cough\n",
    "- sore throat\n",
    "- headache\n",
    "\n",
    "For this project data was used ranging from the beginning of 2015 until July 2019, so over approximately four and a half years. Since ILI rates are reported on a weekly basis, we also used Google Trends data on a weekly basis. Therefore the data amounts to around 230 data points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
